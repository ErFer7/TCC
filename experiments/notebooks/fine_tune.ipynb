{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from json import load\n",
    "\n",
    "from unsloth import FastVisionModel\n",
    "from unsloth import is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "from scripts.authentication import authenticate_huggingface\n",
    "from scripts.data import LesionData, DatasetAnalysis\n",
    "from scripts.messages import create_training_message\n",
    "\n",
    "import scripts.definitions as defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIZATION = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(defs.DATA_PATH, 'stt_data', 'training_dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    training_dataset = [LesionData(**data) for data in load(file)]\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'training_dataset_analysis.json'), 'r', encoding='utf-8') as file:\n",
    "    training_dataset_analysis = DatasetAnalysis(**load(file))\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'stt_data', 'validation_dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    validation_dataset = [LesionData(**data) for data in load(file)]\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'validation_dataset_analysis.json'), 'r', encoding='utf-8') as file:\n",
    "    validation_dataset_analysis = DatasetAnalysis(**load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação das mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_messages = []\n",
    "\n",
    "for lesion_data in training_dataset:\n",
    "    lesion_data.analysis = training_dataset_analysis\n",
    "    training_messages.append(create_training_message(lesion_data))\n",
    "\n",
    "validation_messages = generate_training_messages(validation_dataset, validation_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização do LLaMa 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    'unsloth/Llama-3.2-11B-Vision-Instruct',\n",
    "    load_in_4bit = False,\n",
    "    use_gradient_checkpointing = 'unsloth',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "\n",
    "    r=64,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    random_state=3407,\n",
    "    use_rslora=True,\n",
    "    loftq_config=None\n",
    ")\n",
    "\n",
    "FastVisionModel.for_training(model)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset=training_messages,\n",
    "    eval_dataset=validation_messages,\n",
    "    args=SFTConfig(\n",
    "        eval_strategy='steps',\n",
    "        learning_rate=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type='constant',\n",
    "        seed=3407,\n",
    "        bf16=is_bf16_supported(),\n",
    "        fp16=not is_bf16_supported(),\n",
    "        remove_unused_columns=False,\n",
    "        optim='paged_adamw_32bit',\n",
    "        report_to='tensorboard',\n",
    "        logging_steps=0.05,\n",
    "        output_dir='outputs',\n",
    "        dataset_text_field='',\n",
    "        dataset_kwargs={'skip_prepare_dataset': True},\n",
    "        dataset_num_proc=4,\n",
    "        max_seq_length=2048\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = trainer.model\n",
    "\n",
    "model.save_pretrained(f'../weights/LLaMA_DERM_QLoRA_{training_dataset_size}_11B')\n",
    "tokenizer.save_pretrained(f'../weights/LLaMA_DERM_QLoRA_{training_dataset_size}_11B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
