{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import makedirs\n",
    "from json import load, dump\n",
    "from datetime import datetime\n",
    "\n",
    "from unsloth import FastVisionModel\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from scripts.authentication import authenticate_huggingface\n",
    "from scripts.messages import add_inference_message, format_prompt\n",
    "from scripts.data import LesionData, DatasetAnalysis\n",
    "from scripts.test import Test, TestResult, GenerationParameters\n",
    "\n",
    "import scripts.definitions as defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = defs.BASE_MODEL_NAME\n",
    "QUANTIZED = False  # Isso é sobreescrito no caso de modelos treinados\n",
    "TEST_ON_TRAINING = False  # Testa o modelo sobre os dados de treinamento\n",
    "USE_CACHE = False\n",
    "TEMPERATURE = 0.005\n",
    "\n",
    "with open(join(defs.TRAINING_PATH, 'models.json'), 'r', encoding='utf-8') as file:\n",
    "    models = {model_name: defs.Model(**model) for model_name, model in load(file).items()}\n",
    "\n",
    "model_stats = models[MODEL]\n",
    "model_path = ''\n",
    "\n",
    "if model_stats.local:\n",
    "    model_path = join(defs.RESULTS_PATH, 'adapter_weights', MODEL)\n",
    "else:\n",
    "    model_path = MODEL\n",
    "\n",
    "quantized = model_stats.quantized if model_stats.quantized is not None else QUANTIZED\n",
    "prompt_template = ''\n",
    "prompt_type = model_stats.prompt_type\n",
    "\n",
    "match prompt_type:\n",
    "    case defs.PromptType.SIMPLE_CLASSIFICATION:\n",
    "        prompt_template = defs.SIMPLE_CLASSIFICATION_PROMPT_TEMPLATE\n",
    "    case defs.PromptType.REPORT:\n",
    "        prompt_template = defs.REPORT_PROMPT_TEMPLATE\n",
    "    case _:\n",
    "        raise ValueError('Invalid model type')\n",
    "\n",
    "model_version = model_stats.version\n",
    "model_size = model_stats.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(defs.DATA_PATH, 'stt_data', 'training_dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    training_dataset = [LesionData(**data) for data in load(file)]\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'training_dataset_analysis.json'), 'r', encoding='utf-8') as file:\n",
    "    training_dataset_analysis = DatasetAnalysis(**load(file))\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'stt_data', 'test_dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    test_dataset = [LesionData(**data) for data in load(file)]\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'test_dataset_analysis.json'), 'r', encoding='utf-8') as file:\n",
    "    test_dataset_analysis = DatasetAnalysis(**load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_path,\n",
    "    load_in_4bit=quantized,\n",
    "    use_gradient_checkpointing='unsloth'\n",
    ")\n",
    "\n",
    "FastVisionModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = format_prompt(prompt_template, prompt_type, training_dataset_analysis)\n",
    "messages = add_inference_message(formatted_prompt)\n",
    "\n",
    "test_name = f'{MODEL}_test_{datetime.now().isoformat()}'.strip('unsloth/')\n",
    "\n",
    "test = Test(\n",
    "    tested_model=MODEL.strip('unsloth/'),\n",
    "    model=model_stats,\n",
    "    generation_parameters=GenerationParameters(\n",
    "        max_new_tokens=defs.MAX_TOKENS,\n",
    "        use_cache=USE_CACHE,\n",
    "        temperature=TEMPERATURE\n",
    "    ),\n",
    "    start_time=datetime.now(),\n",
    "    end_time=None,\n",
    "    results_on_test_data=[],\n",
    "    results_on_training_data=[],\n",
    ")\n",
    "\n",
    "tests_path = join(defs.RESULTS_PATH, 'tests')\n",
    "\n",
    "makedirs(tests_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes sobre os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "for idx, exam in enumerate(tqdm(test_dataset, desc='Testing on test data: ')):\n",
    "    image_path = join(defs.DATA_PATH, 'stt_raw_data', 'dataset', 'images', exam.image)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors='pt',\n",
    "    ).to('cuda')\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=defs.MAX_TOKENS,\n",
    "        use_cache=USE_CACHE,\n",
    "        temperature=TEMPERATURE\n",
    "    )\n",
    "\n",
    "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_message = output.split('assistant')[-1].strip()\n",
    "    result = TestResult(\n",
    "        exam_id=exam.exam_id,\n",
    "        image=exam.image,\n",
    "        answer=assistant_message\n",
    "    )\n",
    "\n",
    "    test.results_on_test_data.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes sobre os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_ON_TRAINING:\n",
    "    for idx, exam in enumerate(tqdm(training_dataset, desc='Testing on training data: ')):\n",
    "        image_path = join(defs.DATA_PATH, 'stt_raw_data', 'dataset', 'images', exam.image)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            image,\n",
    "            input_text,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors='pt',\n",
    "        ).to('cuda')\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=defs.MAX_TOKENS,\n",
    "            use_cache=USE_CACHE,\n",
    "            temperature=TEMPERATURE\n",
    "        )\n",
    "\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        assistant_message = result.split('assistant')[-1].strip()\n",
    "        result = TestResult(\n",
    "            exam_id=exam.exam_id,\n",
    "            image=exam.image,\n",
    "            answer=assistant_message\n",
    "        )\n",
    "\n",
    "        test.results_on_training_data.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvamento do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.end_time = datetime.now()\n",
    "\n",
    "test_path = join(tests_path, f'{test_name}.json')\n",
    "\n",
    "with open(test_path, 'w+', encoding='utf-8') as file:\n",
    "    dump(test.model_dump(), file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
