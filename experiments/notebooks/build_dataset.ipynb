{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import makedirs\n",
    "from json import load, dump\n",
    "from re import search\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scripts.data import analyse_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem dos IDs de exames de aproximação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = join('..', 'data')\n",
    "\n",
    "with open(join(DATA_PATH, 'stt_raw_data', 'dataset', 'dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "aproximation_data = {}\n",
    "\n",
    "for exam in data:\n",
    "    aproximation_series = list(filter(lambda s: search(r'LesÃ£o \\d+.', s['seriesdescription']), exam['series']))\n",
    "\n",
    "    if len(aproximation_series) == 0:\n",
    "        continue\n",
    "\n",
    "    aproximation_exam = {'id': exam['id_exame'], 'images': []}\n",
    "\n",
    "    for series in aproximation_series:\n",
    "        aproximation_exam['images'] += series['instances']\n",
    "\n",
    "    aproximation_data[exam['id_exame']] = aproximation_exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de CSV para JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(DATA_PATH, 'stt_raw_data', 'REDE_QUALIDADE-laudos-reemitidos.csv'))\n",
    "\n",
    "REPLACEMENTS = {\n",
    "    '\\\\n': '\\n',\n",
    "    '<br />': '\\n',\n",
    "    '&emsp;': ' ',\n",
    "    '&lt;': '<',\n",
    "    '&gt;': '>',\n",
    "    '–': '-',\n",
    "}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    exam_id = int(row['id_exame'])\n",
    "\n",
    "    if exam_id not in aproximation_data:\n",
    "        continue\n",
    "\n",
    "    report = row['laudo']\n",
    "\n",
    "    for pattern, replacement in REPLACEMENTS.items():\n",
    "        report = report.replace(pattern, replacement)\n",
    "\n",
    "    aproximation_data[exam_id]['report'] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos laudos estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementary_lesions_domain = [\n",
    "    'Mácula/mancha',\n",
    "    'Pápula',\n",
    "    'Placa',\n",
    "    'Nódulo',\n",
    "    'Vesícula',\n",
    "    'Pústula',\n",
    "    'Bolha',\n",
    "    'Cisto',\n",
    "    'Comedão',\n",
    "    'Urtica/ponfo',\n",
    "    'Púrpura',\n",
    "    'Petéquia',\n",
    "    'Equimose',\n",
    "    'Telangectasias',\n",
    "    'Úlcera',\n",
    "    'Ausente',\n",
    "    'Tumor'\n",
    "]\n",
    "\n",
    "secondary_lesions_domain = [\n",
    "    'Escamas',\n",
    "    'Crostas',\n",
    "    'Exulceração',\n",
    "    'Erosão',\n",
    "    'Fissura',\n",
    "    'Liquenificação',\n",
    "    'Atrofia',\n",
    "    'Cicatriz',\n",
    "    'Ausente',\n",
    "    'Escoriação',\n",
    "    'Ceratose',\n",
    "    'Alopécia',\n",
    "    'Maceração'\n",
    "]\n",
    "\n",
    "coloration_domain = [\n",
    "    'Eritematosa (avermelhada)',\n",
    "    'Castanha',\n",
    "    'Negra',\n",
    "    'Perlácea',\n",
    "    'Violácea',\n",
    "    'Azulada',\n",
    "    'Hipo/acrômica (despigmentada)',\n",
    "    'Eucrômica',\n",
    "    'Amarelada',\n",
    "    'Eucrômica'\n",
    "]\n",
    "\n",
    "morphology_domain = [\n",
    "    'Linear',\n",
    "    'Zosteriforme',\n",
    "    'Gutata',\n",
    "    'Lenticular',\n",
    "    'Anular',\n",
    "    'Numular',\n",
    "    'Policíclica',\n",
    "    'Circinada',\n",
    "    'Circular ou Arredondada',\n",
    "    'Irregular/assimétrica',\n",
    "    'Séssil / Pedunculada',\n",
    "    'Papilomatosa / Verrucosa',\n",
    "    'Intertriginosa',\n",
    "    'Arboriforme',\n",
    "    'Puntiforme',\n",
    "    'Folicular'\n",
    "]\n",
    "\n",
    "size_domain = [\n",
    "    '< 1',\n",
    "    '1 a 2',\n",
    "    '2 a 4',\n",
    "    '> 4'\n",
    "]\n",
    "\n",
    "distribution_domain = [\n",
    "    'Única',\n",
    "    'Localizada',\n",
    "    'Disseminada',\n",
    "    'Generalizada'\n",
    "]\n",
    "\n",
    "risk_domain = [\n",
    "    'VERMELHA - QUADROS AGUDOS E GRAVES',\n",
    "    'AMARELA - ENCAMINHAMENTO COM PRIORIDADE PARA O AMBULATÓRIO DE REFERÊNCIA TERCIÁRIO',\n",
    "    'AMARELA - ENCAMINHAMENTO COM PRIORIDADE PARA O AMBULATÓRIO DE REFERÊNCIA',  # Versão alternativa\n",
    "    'VERDE - AVALIAÇÃO CLÍNICO-CIRURGIA COM ESPECIALISTA',\n",
    "    'AZUL - TRATAMENTO NA UNIDADE BÁSICA DE SAÚDE (UBS)',\n",
    "    'BRANCA - SEM NECESSIDADE DE INTERVENÇÃO OU ACOMPANHAMENTO'\n",
    "]\n",
    "\n",
    "for exam_id, exam in aproximation_data.items():\n",
    "    # O [1:] remove e o tipo de laudo. Sempre é \"Exame de Teledermatologia\"\n",
    "    report_parts = list(map(str.strip, exam['report'].split('\\n')))[1:]\n",
    "\n",
    "    structured_report = {\n",
    "        'elementary_lesions': [],\n",
    "        'secondary_lesions': [],\n",
    "        'coloration': [],\n",
    "        'morphology': [],\n",
    "        'size': '',\n",
    "        'local': '',\n",
    "        'distribution': [],\n",
    "        'risk': '',\n",
    "        'skin_lesion': '',\n",
    "        'observations': ''\n",
    "    }\n",
    "\n",
    "    while report_parts[0] in elementary_lesions_domain:\n",
    "        structured_report['elementary_lesions'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in secondary_lesions_domain:\n",
    "        structured_report['secondary_lesions'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in coloration_domain:\n",
    "        structured_report['coloration'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in morphology_domain:\n",
    "        structured_report['morphology'].append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in size_domain:\n",
    "        structured_report['size'] = report_parts.pop(0)\n",
    "\n",
    "    structured_report['local'] = report_parts.pop(0)  # Sem domínio definido\n",
    "\n",
    "    while report_parts[0] in distribution_domain:\n",
    "        structured_report['distribution'].append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in risk_domain:\n",
    "        structured_report['risk'] = report_parts.pop(0)\n",
    "\n",
    "    structured_report['skin_lesion'] = report_parts.pop(0)  # Sem domínio definido\n",
    "\n",
    "    structured_report['observations'] = '\\n'.join(report_parts)\n",
    "\n",
    "    aproximation_data[exam_id]['report'] = structured_report\n",
    "\n",
    "approximation_data_list = []\n",
    "\n",
    "for exam_id, exam in aproximation_data.items():\n",
    "    approximation_data_list.append(exam)\n",
    "\n",
    "makedirs(join(DATA_PATH, 'stt_data'), exist_ok=True)\n",
    "\n",
    "with open(join(DATA_PATH, 'stt_data', 'dataset.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(approximation_data_list, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "data_analysis = analyse_dataset(approximation_data_list, DATA_PATH, 'dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de lesões raras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(filter(lambda exam: data_analysis['skin_lesion_distribution']['classes'][exam['report']['skin_lesion']]['value'] >= 10, approximation_data_list))\n",
    "\n",
    "data_analysis = analyse_dataset(data, DATA_PATH, 'filtered_dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seccionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PROPORTION = 0.8\n",
    "VALIDATION_PROPORTION = 0.1\n",
    "TEST_PROPORTION = 0.1\n",
    "\n",
    "labels = [sample['report']['skin_lesion'] for sample in data]\n",
    "\n",
    "training_data, test_data = train_test_split(\n",
    "    data,\n",
    "    test_size=TEST_PROPORTION,\n",
    "    train_size=TRAINING_PROPORTION,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "training_labels = [sample['report']['skin_lesion'] for sample in training_data]\n",
    "\n",
    "_, validation_data = train_test_split(\n",
    "    training_data,\n",
    "    test_size=VALIDATION_PROPORTION / TRAINING_PROPORTION,\n",
    "    stratify=training_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dataset_pairs = ((training_data, 'training_dataset.json'),\n",
    "                 (test_data, 'test_dataset.json'),\n",
    "                 (validation_data, 'validation_dataset.json'))\n",
    "\n",
    "for dataset, dataset_name in dataset_pairs:\n",
    "    with open(join(DATA_PATH, 'stt_data', dataset_name), 'w', encoding='utf-8') as file:\n",
    "        dump(dataset, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    analyse_dataset(dataset, DATA_PATH, dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
