{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import makedirs\n",
    "from json import load, dump\n",
    "from re import search\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scripts.data import analyse_dataset, RawData, RawApproximationExam, RawReport, Report, ApproximationExam\n",
    "\n",
    "import scripts.definitions as defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem dos IDs de exames de aproximação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(defs.DATA_PATH, 'stt_raw_data', 'dataset', 'dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    dataset = [RawData(**data) for data in load(file)]\n",
    "\n",
    "raw_approximation_exams = {}\n",
    "\n",
    "for raw_exam in dataset:\n",
    "    approximation_series = list(filter(lambda series: search(\n",
    "        r'LesÃ£o \\d+.', series.seriesdescription), raw_exam.series))\n",
    "\n",
    "    if len(approximation_series) == 0:\n",
    "        continue\n",
    "\n",
    "    raw_approximation_exam = RawApproximationExam(exam_id=0, images=[], report='')\n",
    "\n",
    "    for series in approximation_series:\n",
    "        raw_approximation_exam.images += series.instances\n",
    "\n",
    "    raw_approximation_exams[raw_exam.id_exame] = raw_approximation_exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de CSV para JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(defs.DATA_PATH, 'stt_raw_data', 'REDE_QUALIDADE-laudos-reemitidos.csv'))\n",
    "\n",
    "REPLACEMENTS = {\n",
    "    '\\\\n': '\\n',\n",
    "    '<br />': '\\n',\n",
    "    '&emsp;': ' ',\n",
    "    '&lt;': '<',\n",
    "    '&gt;': '>',\n",
    "    '–': '-',\n",
    "}\n",
    "\n",
    "for _, raw_report in df.iterrows():\n",
    "    raw_report = RawReport(**raw_report.to_dict())\n",
    "\n",
    "    exam_id = int(raw_report.id_exame)\n",
    "\n",
    "    if exam_id not in raw_approximation_exams:\n",
    "        continue\n",
    "\n",
    "    report = raw_report.laudo\n",
    "\n",
    "    for pattern, replacement in REPLACEMENTS.items():\n",
    "        report = report.replace(pattern, replacement)\n",
    "\n",
    "    raw_approximation_exams[exam_id].report = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos laudos estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = {}\n",
    "\n",
    "for exam_id, raw_exam in raw_approximation_exams.items():\n",
    "    # O [1:] remove o tipo de laudo. Sempre é \"Exame de Teledermatologia\"\n",
    "    report_parts = list(map(str.strip, raw_exam.report.splitlines()))[1:]\n",
    "\n",
    "    structured_report = Report(\n",
    "        elementary_lesions=[],\n",
    "        secondary_lesions=[],\n",
    "        coloration=[],\n",
    "        morphology=[],\n",
    "        size='',\n",
    "        local='',\n",
    "        distribution=[],\n",
    "        risk='',\n",
    "        skin_lesion='',\n",
    "        conclusion='',\n",
    "    )\n",
    "\n",
    "    while report_parts[0] in defs.ELEMENTARY_LESIONS_DOMAIN:\n",
    "        structured_report.elementary_lesions.append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in defs.SECONDARY_LESIONS_DOMAIN:\n",
    "        structured_report.secondary_lesions.append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in defs.COLORATION_DOMAIN:\n",
    "        structured_report.coloration.append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in defs.MORPHOLOGY_DOMAIN:\n",
    "        structured_report.morphology.append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in defs.SIZE_DOMAIN:\n",
    "        structured_report.size = report_parts.pop(0)\n",
    "\n",
    "    structured_report.local = report_parts.pop(0)  # Sem domínio definido\n",
    "\n",
    "    while report_parts[0] in defs.DISTRIBUTION_DOMAIN:\n",
    "        structured_report.distribution.append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in defs.RISK_DOMAIN:\n",
    "        structured_report.risk = report_parts.pop(0)\n",
    "\n",
    "    if report_parts[0] in defs.SKIN_LESION_DOMAIN:\n",
    "        structured_report.skin_lesion = report_parts.pop(0)\n",
    "\n",
    "    structured_report.conclusion = '\\n'.join(report_parts)\n",
    "\n",
    "    if len(structured_report.secondary_lesions) == 0:\n",
    "        structured_report.secondary_lesions = ['Nenhuma']\n",
    "\n",
    "    reports[exam_id] = structured_report\n",
    "\n",
    "approximation_exams: list[ApproximationExam] = []\n",
    "\n",
    "for exam_id, raw_exam in raw_approximation_exams.items():\n",
    "    for image in raw_exam.images:\n",
    "        approximation_exam = ApproximationExam(exam_id=exam_id, image=image, report=reports[exam_id])\n",
    "        approximation_exams.append(approximation_exam)\n",
    "\n",
    "approximation_exams_dicts = [approximation_exam.model_dump() for approximation_exam in approximation_exams]\n",
    "\n",
    "makedirs(join(defs.DATA_PATH, 'stt_data'), exist_ok=True)\n",
    "\n",
    "with open(join(defs.DATA_PATH, 'stt_data', 'dataset.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(approximation_exams_dicts, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "data_analysis = analyse_dataset(approximation_exams, defs.DATA_PATH, 'dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de lesões raras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(filter(lambda data: data_analysis.skin_lesion_distribution.classes[data.report.skin_lesion].count >= 10,\n",
    "                      approximation_exams))\n",
    "\n",
    "_ = analyse_dataset(dataset, defs.DATA_PATH, 'filtered_dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seccionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [data.report.skin_lesion for data in dataset]\n",
    "\n",
    "training_data, test_data = train_test_split(\n",
    "    dataset,\n",
    "    test_size=defs.TEST_PROPORTION,\n",
    "    train_size=defs.TRAINING_PROPORTION,\n",
    "    stratify=labels,\n",
    "    random_state=defs.STATIC_RANDOM_STATE\n",
    ")\n",
    "\n",
    "training_labels = [data.report.skin_lesion for data in training_data]\n",
    "\n",
    "_, validation_data = train_test_split(\n",
    "    training_data,\n",
    "    test_size=defs.VALIDATION_PROPORTION / defs.TRAINING_PROPORTION,\n",
    "    stratify=training_labels,\n",
    "    random_state=defs.STATIC_RANDOM_STATE\n",
    ")\n",
    "\n",
    "dataset_pairs = ((training_data, 'training_dataset.json'),\n",
    "                 (test_data, 'test_dataset.json'),\n",
    "                 (validation_data, 'validation_dataset.json'))\n",
    "\n",
    "\n",
    "for dataset, dataset_name in dataset_pairs:\n",
    "    dataset_dict = [data.model_dump() for data in dataset]\n",
    "\n",
    "    with open(join(defs.DATA_PATH, 'stt_data', dataset_name), 'w', encoding='utf-8') as file:\n",
    "        dump(dataset_dict, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    _ = analyse_dataset(dataset, defs.DATA_PATH, dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
