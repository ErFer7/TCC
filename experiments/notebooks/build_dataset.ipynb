{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from os import makedirs\n",
    "from json import load, dump\n",
    "from re import search\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem dos IDs de exames de aproximação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = join('..', 'data')\n",
    "\n",
    "with open(join(DATA_PATH, 'stt_raw_data', 'dataset', 'dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "aproximation_data = {}\n",
    "\n",
    "for exam in data:\n",
    "    aproximation_series = list(filter(lambda s: search(r'LesÃ£o \\d+.', s['seriesdescription']), exam['series']))\n",
    "\n",
    "    if len(aproximation_series) == 0:\n",
    "        continue\n",
    "\n",
    "    aproximation_exam = {'id': exam['id_exame'], 'images': []}\n",
    "\n",
    "    for series in aproximation_series:\n",
    "        aproximation_exam['images'] += series['instances']\n",
    "\n",
    "    aproximation_data[exam['id_exame']] = aproximation_exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de CSV para JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(DATA_PATH, 'stt_raw_data', 'REDE_QUALIDADE-laudos-reemitidos.csv'))\n",
    "\n",
    "REPLACEMENTS = {\n",
    "    '\\\\n': '\\n',\n",
    "    '<br />': '\\n',\n",
    "    '&emsp;': ' ',\n",
    "    '&lt;': '<',\n",
    "    '&gt;': '>',\n",
    "    '–': '-',\n",
    "}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    exam_id = int(row['id_exame'])\n",
    "\n",
    "    if exam_id not in aproximation_data:\n",
    "        continue\n",
    "\n",
    "    report = row['laudo']\n",
    "\n",
    "    for pattern, replacement in REPLACEMENTS.items():\n",
    "        report = report.replace(pattern, replacement)\n",
    "\n",
    "    aproximation_data[exam_id]['report'] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos laudos estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementary_lesions_domain = [\n",
    "    'Mácula/mancha',\n",
    "    'Pápula',\n",
    "    'Placa',\n",
    "    'Nódulo',\n",
    "    'Vesícula',\n",
    "    'Pústula',\n",
    "    'Bolha',\n",
    "    'Cisto',\n",
    "    'Comedão',\n",
    "    'Urtica/ponfo',\n",
    "    'Púrpura',\n",
    "    'Petéquia',\n",
    "    'Equimose',\n",
    "    'Telangectasias',\n",
    "    'Úlcera',\n",
    "    'Ausente',\n",
    "    'Tumor'\n",
    "]\n",
    "\n",
    "secondary_lesions_domain = [\n",
    "    'Escamas',\n",
    "    'Crostas',\n",
    "    'Exulceração',\n",
    "    'Erosão',\n",
    "    'Fissura',\n",
    "    'Liquenificação',\n",
    "    'Atrofia',\n",
    "    'Cicatriz',\n",
    "    'Ausente',\n",
    "    'Escoriação',\n",
    "    'Ceratose',\n",
    "    'Alopécia',\n",
    "    'Maceração'\n",
    "]\n",
    "\n",
    "coloration_domain = [\n",
    "    'Eritematosa (avermelhada)',\n",
    "    'Castanha',\n",
    "    'Negra',\n",
    "    'Perlácea',\n",
    "    'Violácea',\n",
    "    'Azulada',\n",
    "    'Hipo/acrômica (despigmentada)',\n",
    "    'Eucrômica',\n",
    "    'Amarelada',\n",
    "    'Eucrômica'\n",
    "]\n",
    "\n",
    "morphology_domain = [\n",
    "    'Linear',\n",
    "    'Zosteriforme',\n",
    "    'Gutata',\n",
    "    'Lenticular',\n",
    "    'Anular',\n",
    "    'Numular',\n",
    "    'Policíclica',\n",
    "    'Circinada',\n",
    "    'Circular ou Arredondada',\n",
    "    'Irregular/assimétrica',\n",
    "    'Séssil / Pedunculada',\n",
    "    'Papilomatosa / Verrucosa',\n",
    "    'Intertriginosa',\n",
    "    'Arboriforme',\n",
    "    'Puntiforme',\n",
    "    'Folicular'\n",
    "]\n",
    "\n",
    "size_domain = [\n",
    "    '< 1',\n",
    "    '1 a 2',\n",
    "    '2 a 4',\n",
    "    '> 4'\n",
    "]\n",
    "\n",
    "distribution_domain = [\n",
    "    'Única',\n",
    "    'Localizada',\n",
    "    'Disseminada',\n",
    "    'Generalizada'\n",
    "]\n",
    "\n",
    "risk_domain = [\n",
    "    'VERMELHA - QUADROS AGUDOS E GRAVES',\n",
    "    'AMARELA - ENCAMINHAMENTO COM PRIORIDADE PARA O AMBULATÓRIO DE REFERÊNCIA TERCIÁRIO',\n",
    "    'AMARELA - ENCAMINHAMENTO COM PRIORIDADE PARA O AMBULATÓRIO DE REFERÊNCIA',  # Versão alternativa\n",
    "    'VERDE - AVALIAÇÃO CLÍNICO-CIRURGIA COM ESPECIALISTA',\n",
    "    'AZUL - TRATAMENTO NA UNIDADE BÁSICA DE SAÚDE (UBS)',\n",
    "    'BRANCA - SEM NECESSIDADE DE INTERVENÇÃO OU ACOMPANHAMENTO'\n",
    "]\n",
    "\n",
    "for exam_id, exam in aproximation_data.items():\n",
    "    # O [1:] remove e o tipo de laudo. Sempre é \"Exame de Teledermatologia\"\n",
    "    report_parts = list(map(str.strip, exam['report'].split('\\n')))[1:]\n",
    "\n",
    "    structured_report = {\n",
    "        'elementary_lesions': [],\n",
    "        'secondary_lesions': [],\n",
    "        'coloration': [],\n",
    "        'morphology': [],\n",
    "        'size': '',\n",
    "        'local': '',\n",
    "        'distribution': [],\n",
    "        'risk': '',\n",
    "        'skin_lesion': '',\n",
    "        'observations': ''\n",
    "    }\n",
    "\n",
    "    while report_parts[0] in elementary_lesions_domain:\n",
    "        structured_report['elementary_lesions'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in secondary_lesions_domain:\n",
    "        structured_report['secondary_lesions'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in coloration_domain:\n",
    "        structured_report['coloration'].append(report_parts.pop(0))\n",
    "\n",
    "    while report_parts[0] in morphology_domain:\n",
    "        structured_report['morphology'].append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in size_domain:\n",
    "        structured_report['size'] = report_parts.pop(0)\n",
    "\n",
    "    structured_report['local'] = report_parts.pop(0)  # Sem domínio definido\n",
    "\n",
    "    while report_parts[0] in distribution_domain:\n",
    "        structured_report['distribution'].append(report_parts.pop(0))\n",
    "\n",
    "    if report_parts[0] in risk_domain:\n",
    "        structured_report['risk'] = report_parts.pop(0)\n",
    "\n",
    "    structured_report['skin_lesion'] = report_parts.pop(0)  # Sem domínio definido\n",
    "\n",
    "    structured_report['observations'] = '\\n'.join(report_parts)\n",
    "\n",
    "    aproximation_data[exam_id]['report'] = structured_report\n",
    "\n",
    "aproximation_data_list = []\n",
    "\n",
    "for exam_id, exam in aproximation_data.items():\n",
    "    aproximation_data_list.append(exam)\n",
    "\n",
    "makedirs(join(DATA_PATH, 'stt_data'), exist_ok=True)\n",
    "\n",
    "with open(join(DATA_PATH, 'stt_data', 'dataset.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(aproximation_data_list, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_PATH, 'stt_data', 'dataset.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "data_analysis = {\n",
    "    'total_size': 0,\n",
    "    'average_images_per_exam': 0,\n",
    "    'elementary_lesions_distribution': {},\n",
    "    'secondary_lesions_distribution': {},\n",
    "    'coloration_distribution': {},\n",
    "    'morphology_distribution': {},\n",
    "    'size_distribution': {},\n",
    "    'local_distribution': {},\n",
    "    'distribution_distribution': {},\n",
    "    'risk_distribution': {},\n",
    "    'skin_lesion_distribution': {}\n",
    "}\n",
    "\n",
    "data_analysis['total_size'] = len(data)\n",
    "data_analysis['average_images_per_exam'] = sum(len(exam['images']) for exam in data) / data_analysis['total_size']\n",
    "\n",
    "for exam in data:\n",
    "    report = exam['report']\n",
    "\n",
    "    for elementary_lesion in report['elementary_lesions']:\n",
    "        if elementary_lesion not in data_analysis['elementary_lesions_distribution']:\n",
    "            data_analysis['elementary_lesions_distribution'][elementary_lesion] = 0\n",
    "\n",
    "        data_analysis['elementary_lesions_distribution'][elementary_lesion] += 1\n",
    "\n",
    "    for secondary_lesion in report['secondary_lesions']:\n",
    "        if secondary_lesion not in data_analysis['secondary_lesions_distribution']:\n",
    "            data_analysis['secondary_lesions_distribution'][secondary_lesion] = 0\n",
    "\n",
    "        data_analysis['secondary_lesions_distribution'][secondary_lesion] += 1\n",
    "\n",
    "    for coloration in report['coloration']:\n",
    "        if coloration not in data_analysis['coloration_distribution']:\n",
    "            data_analysis['coloration_distribution'][coloration] = 0\n",
    "\n",
    "        data_analysis['coloration_distribution'][coloration] += 1\n",
    "\n",
    "    for morphology in report['morphology']:\n",
    "        if morphology not in data_analysis['morphology_distribution']:\n",
    "            data_analysis['morphology_distribution'][morphology] = 0\n",
    "\n",
    "        data_analysis['morphology_distribution'][morphology] += 1\n",
    "\n",
    "    if report['size'] not in data_analysis['size_distribution']:\n",
    "        data_analysis['size_distribution'][report['size']] = 0\n",
    "\n",
    "    data_analysis['size_distribution'][report['size']] += 1\n",
    "\n",
    "    if report['local'] not in data_analysis['local_distribution']:\n",
    "        data_analysis['local_distribution'][report['local']] = 0\n",
    "\n",
    "    data_analysis['local_distribution'][report['local']] += 1\n",
    "\n",
    "    for distribution in report['distribution']:\n",
    "        if distribution not in data_analysis['distribution_distribution']:\n",
    "            data_analysis['distribution_distribution'][distribution] = 0\n",
    "\n",
    "        data_analysis['distribution_distribution'][distribution] += 1\n",
    "\n",
    "    if report['risk'] not in data_analysis['risk_distribution']:\n",
    "        data_analysis['risk_distribution'][report['risk']] = 0\n",
    "\n",
    "    data_analysis['risk_distribution'][report['risk']] += 1\n",
    "\n",
    "    if report['skin_lesion'] not in data_analysis['skin_lesion_distribution']:\n",
    "        data_analysis['skin_lesion_distribution'][report['skin_lesion']] = 0\n",
    "\n",
    "    data_analysis['skin_lesion_distribution'][report['skin_lesion']] += 1\n",
    "\n",
    "with open(join(DATA_PATH, 'data_analysis.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(data_analysis, file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
