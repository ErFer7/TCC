{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de CSV para JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from json import dump, load\n",
    "\n",
    "DATA_DIR = join('..', 'data')\n",
    "\n",
    "df = pd.read_csv(join(DATA_DIR, 'STT', 'REDE_QUALIDADE-laudos-reemitidos.csv'))\n",
    "json_data = []\n",
    "\n",
    "HTML_REPLACEMENTS = {\n",
    "    '\\\\n': '\\n',\n",
    "    '<br />': '\\n',\n",
    "    '&emsp;': ' ',\n",
    "    '&lt;': '<',\n",
    "    '&gt;': '>'\n",
    "}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    laudo_text = row['laudo']\n",
    "\n",
    "    for pattern, replacement in HTML_REPLACEMENTS.items():\n",
    "        laudo_text = laudo_text.replace(pattern, replacement)\n",
    "\n",
    "    json_data.append({\n",
    "        'id_solicitacao': row['id_solicitacao'],\n",
    "        'id_exame': row['id_exame'],\n",
    "        'id_laudo': row['id_laudo'],\n",
    "        'laudo': laudo_text\n",
    "    })\n",
    "\n",
    "with open(join(DATA_DIR, 'laudos.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(json_data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração do texto legível com os laudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_DIR, 'laudos.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "with open(join(DATA_DIR, 'laudos.txt'), 'w', encoding='utf-8') as file:\n",
    "    for item in data:\n",
    "        file.write(f'ID da solicitação: {item[\"id_solicitacao\"]}\\n')\n",
    "        file.write(f'ID do exame: {item[\"id_exame\"]}\\n')\n",
    "        file.write(f'ID do laudo: {item[\"id_laudo\"]}\\n\\n')\n",
    "        file.write(f'Laudo: {item[\"laudo\"]}\\n')\n",
    "        file.write(120 * '-' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos laudos estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search\n",
    "\n",
    "\n",
    "with open(join(DATA_DIR, 'laudos.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "structured_reports = []\n",
    "\n",
    "for item in data:\n",
    "    report_parts = list(map(str.strip, item['laudo'].split('\\n')))\n",
    "\n",
    "    report_type = report_parts.pop(0)\n",
    "    description = []\n",
    "\n",
    "    while not bool(search(r'\\d', report_parts[0])):\n",
    "        description.append(report_parts.pop(0))\n",
    "\n",
    "    count = report_parts.pop(0)\n",
    "    location = report_parts.pop(0)\n",
    "    spread = []\n",
    "\n",
    "    while not bool(search(r'^(?:AZUL|BRANCA|VERDE|AMARELA).*', report_parts[0])):\n",
    "        spread.append(report_parts.pop(0))\n",
    "\n",
    "    structured_reports.append({\n",
    "        'solicitation_id': item['id_solicitacao'],\n",
    "        'exam_id': item['id_exame'],\n",
    "        'report_id': item['id_laudo'],\n",
    "        'report_type': report_type,\n",
    "        'description': description,\n",
    "        'count': count,\n",
    "        'location': location,\n",
    "        'spread': spread,\n",
    "        'attention_class': report_parts[0],\n",
    "        'lesion': report_parts[1],\n",
    "        'recommendations': '\\n'.join(report_parts[2:])\n",
    "    })\n",
    "\n",
    "with open(join(DATA_DIR, 'reports.json'), 'w', encoding='utf-8') as file:\n",
    "    dump(structured_reports, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "\n",
    "with open(join(DATA_DIR, 'reports.json'), 'r', encoding='utf-8') as file:\n",
    "    data = load(file)\n",
    "\n",
    "value_count_by_key = {}\n",
    "\n",
    "exclude_keys = ['solicitation_id', 'exam_id', 'report_id']\n",
    "\n",
    "for entry in data:\n",
    "    for key, value in entry.items():\n",
    "        if key in exclude_keys:\n",
    "            continue\n",
    "        \n",
    "        if key not in value_count_by_key:\n",
    "            value_count_by_key[key] = {}\n",
    "\n",
    "        if type(value) is list:\n",
    "            value = tuple(value)\n",
    "        elif type(value) is str:\n",
    "            value = value.replace('\\n', ' ')\n",
    "\n",
    "        if value not in value_count_by_key[key]:\n",
    "            value_count_by_key[key][value] = 0\n",
    "\n",
    "        value_count_by_key[key][value] += 1\n",
    "\n",
    "result = ''\n",
    "\n",
    "for key, value in value_count_by_key.items():\n",
    "    result += f'{key}:\\n'\n",
    "    total = sum(value.values())\n",
    "\n",
    "    for value, count in sorted(value.items(), key=lambda x: x[1], reverse=True):\n",
    "        result += f'  {value}: {count} - {count / total:.2%}\\n'\n",
    "\n",
    "    result += f'  Total: {total}\\n\\n'\n",
    "\n",
    "with open(join(DATA_DIR, 'reports_key_value_count.txt'), 'w', encoding='utf-8') as file:\n",
    "    file.write(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
