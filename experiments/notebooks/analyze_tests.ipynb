{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "from collections import OrderedDict\n",
    "\n",
    "tests_paths = OrderedDict({\n",
    "    'LLaMA-3.2-11B-Vision-Instruct (Quantizado)': '../analysis/Llama-3.2-11B-Vision-Instruct_test_class_only_quantized.json',\n",
    "    'LLaMA-3.2-11B-Vision-Instruct': '../analysis/Llama-3.2-11B-Vision-Instruct_test_class_only.json',\n",
    "    'LLaMA com QLoRA (450 amostras)': '../analysis/LLaMA_DERM_QLoRA_500_11B_test_class_only.json',\n",
    "    'LLaMA com QLoRA (900 amostras)': '../analysis/LLaMA_DERM_QLoRA_1000_11B_test_class_only.json',\n",
    "    'LLaMA com QLoRA (1800 amostras)': '../analysis/LLaMA_DERM_QLoRA_2000_11B_test_class_only.json',\n",
    "    'LLaMA com QLoRA (5000 amostras)': '../analysis/LLaMA_DERM_QLoRA_5000_11B_test_class_only.json',\n",
    "    'LLaMA com QLoRA (9500 amostras)': '../analysis/LLaMA_DERM_QLoRA_9500_11B_test_class_only.json',\n",
    "    'LLaMA com LoRA (450 amostras)': '../analysis/LLaMA_DERM_LoRA_500_11B_test_class_only.json',\n",
    "    'LLaMA com LoRA (900 amostras)': '../analysis/LLaMA_DERM_LoRA_1000_11B_test_class_only.json',\n",
    "    'LLaMA com LoRA (5000 amostras)': '../analysis/LLaMA_DERM_LoRA_5000_11B_test_class_only.json'\n",
    "})\n",
    "\n",
    "tests = OrderedDict({k: load(open(v)) for k, v in tests_paths.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contagem das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_distribution_table(counter: Counter, total: int, title: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Cria um DataFrame formatado a partir dos dados de um contador.\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'Answer': answer if len(answer) < 50 else answer[:51] + '...',\n",
    "            'Count': count,\n",
    "            'Percentage': count/total * 100\n",
    "        }\n",
    "        for answer, count in counter.items()\n",
    "    ])\n",
    "\n",
    "    df = df.sort_values('Count', ascending=False)\n",
    "    df['Percentage'] = df['Percentage'].map('{:.1f}%'.format)\n",
    "\n",
    "    styled_df = df.style.set_caption(title).set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-weight', 'bold'), ('font-size', '120%')]},\n",
    "        {'selector': 'th', 'props': [('text-align', 'left'), ('background-color', '#f0f0f0')]},\n",
    "        {'selector': 'table', 'props': [('width', '100%')]},\n",
    "    ]).hide(axis='index')\n",
    "\n",
    "    return styled_df\n",
    "\n",
    "\n",
    "def display_model_results(model_name: str, test_data: list[dict[str, str]]):\n",
    "    '''\n",
    "    Exibe a distribuição em tabela dos resultados esperados vs reais para um modelo.\n",
    "    '''\n",
    "\n",
    "    results = test_data['results']\n",
    "    expected_counter = Counter(item['expected'] for item in results)\n",
    "    actual_counter = Counter(item['actual'] for item in results)\n",
    "\n",
    "    total = len(results)\n",
    "\n",
    "    display(HTML(f'<h2>{model_name}</h2>'))\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "        <div>\n",
    "            \"\"\" + create_distribution_table(expected_counter, total, 'Expected Classes Distribution').to_html() + \"\"\"\n",
    "        </div>\n",
    "        <div>\n",
    "            \"\"\" + create_distribution_table(actual_counter, total, 'Model Predictions Distribution').to_html() + \"\"\"\n",
    "        </div>\n",
    "    </div>\n",
    "    <br><hr><br>\n",
    "    \"\"\"))\n",
    "\n",
    "\n",
    "for model_name, test_data in tests.items():\n",
    "    display_model_results(model_name, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento dos testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "DISEASE_CLASSES = [\n",
    "    'melanocytic Nevi',\n",
    "    'melanoma',\n",
    "    'benign keratosis-like lesions',\n",
    "    'basal cell carcinoma',\n",
    "    'actinic keratoses',\n",
    "    'vascular lesions',\n",
    "    'dermatofibroma'\n",
    "]\n",
    "\n",
    "\n",
    "def normalize_disease(text: str) -> str:\n",
    "    '''\n",
    "    Normaliza o nome da doença para um formato padrão.\n",
    "    '''\n",
    "\n",
    "    text = text.lower().strip().strip('.')\n",
    "\n",
    "    variations = {\n",
    "        'melanocytic nevi': 'melanocytic Nevi',\n",
    "        'nevus': 'melanocytic Nevi',\n",
    "        'nevi': 'melanocytic Nevi',\n",
    "        'benign keratosis': 'benign keratosis-like lesions',\n",
    "        'seborrheic keratosis': 'benign keratosis-like lesions',\n",
    "        'basal cell': 'basal cell carcinoma',\n",
    "        'actinic keratosis': 'actinic keratoses',\n",
    "        'vascular': 'vascular lesions'\n",
    "    }\n",
    "\n",
    "    for variant, standard in variations.items():\n",
    "        if variant in text:\n",
    "            return standard\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def classify_answer(text: str) -> str:\n",
    "    '''\n",
    "    Classifica a resposta do modelo em uma classe de doença padrão ou incerta.\n",
    "    '''\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    mentioned_diseases = []\n",
    "    for disease in DISEASE_CLASSES:\n",
    "        if disease.lower() in text:\n",
    "            mentioned_diseases.append(disease)\n",
    "\n",
    "    if len(mentioned_diseases) != 1:\n",
    "        return 'unclear answer'\n",
    "    else:\n",
    "        return mentioned_diseases[0]\n",
    "\n",
    "\n",
    "def process_and_display_results(model_name: str, test_data: list[dict[str, str]]) -> list[tuple[str, str]]:\n",
    "    '''\n",
    "    Processa e exibe os resultados com classificações padronizadas. Retorna uma lista de pares (esperado, classificado).\n",
    "    '''\n",
    "\n",
    "    results = test_data['results']\n",
    "    total = len(results)\n",
    "\n",
    "    processed_results = [\n",
    "        {\n",
    "            'expected': result['expected'],\n",
    "            'actual': result['actual'],\n",
    "            'classified': classify_answer(result['actual'])\n",
    "        }\n",
    "        for result in results\n",
    "    ]\n",
    "\n",
    "    pairs = [(r['expected'], r['classified']) for r in processed_results]\n",
    "\n",
    "    expected_counter = Counter(item['expected'] for item in processed_results)\n",
    "    classified_counter = Counter(item['classified'] for item in processed_results)\n",
    "\n",
    "    display(HTML(f'<h2>{model_name}</h2>'))\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "        <div>\n",
    "            \"\"\" + create_distribution_table(expected_counter, total, 'Expected Classes').to_html() + \"\"\"\n",
    "        </div>\n",
    "        <div>\n",
    "            \"\"\" + create_distribution_table(classified_counter, total, 'Classified Predictions').to_html() + \"\"\"\n",
    "        </div>\n",
    "    </div>\n",
    "    <br><hr><br>\n",
    "    \"\"\"))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for model_name, test_data in tests.items():\n",
    "    all_results[model_name] = process_and_display_results(model_name, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "def analyze_model_performance(pairs: list[tuple[str, str]], model_name: str):\n",
    "    '''\n",
    "    Calcula a acurácia e cria uma visualização da matriz de confusão normalizada.\n",
    "    '''\n",
    "\n",
    "    class_pt_translations = {\n",
    "        'melanocytic Nevi': 'Nevo melanocítico',\n",
    "        'melanoma': 'Melanoma',\n",
    "        'benign keratosis-like lesions': 'Lesões similares à queratose benigna',\n",
    "        'basal cell carcinoma': 'Carcinoma basocelular',\n",
    "        'actinic keratoses': 'Queratose actínica',\n",
    "        'vascular lesions': 'Lesões vasculares',\n",
    "        'dermatofibroma': 'Dermatofibroma',\n",
    "        'unclear answer': 'Resposta incerta'\n",
    "    }\n",
    "\n",
    "    y_true = [p[0] for p in pairs]\n",
    "    x_pred = [p[1] for p in pairs]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, x_pred)\n",
    "\n",
    "    labels = DISEASE_CLASSES + ['unclear answer']\n",
    "\n",
    "    pt_labels = [class_pt_translations[label] for label in labels]\n",
    "    pt_y_true = [class_pt_translations[label] for label in y_true]\n",
    "    pt_x_pred = [class_pt_translations[label] for label in x_pred]\n",
    "\n",
    "    cm = confusion_matrix(pt_y_true, pt_x_pred, labels=pt_labels, normalize='true')\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    heat_map = sns.heatmap(cm,\n",
    "                           annot=True,\n",
    "                           fmt='.1%',\n",
    "                           cmap='Blues',\n",
    "                           xticklabels=pt_labels,\n",
    "                           yticklabels=pt_labels,\n",
    "                           vmin=0,\n",
    "                           vmax=1)\n",
    "    color_bar = heat_map.collections[0].colorbar\n",
    "    color_bar.set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    color_bar.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
    "    plt.title(f'{model_name}\\nAcurácia: {accuracy:.2%}')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/{model_name}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracies = {}\n",
    "for model_name, pairs in all_results.items():\n",
    "    accuracies[model_name] = analyze_model_performance(pairs, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
